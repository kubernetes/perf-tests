{{$PROMETHEUS_SCRAPE_KUBELETS := DefaultParam .PROMETHEUS_SCRAPE_KUBELETS false}}
{{$PROMETHEUS_SCRAPE_WINDOWS_NODES := DefaultParam .PROMETHEUS_SCRAPE_WINDOWS_NODES false}}
{{$PROMETHEUS_CPU_SCALE_FACTOR := DefaultParam .CL2_PROMETHEUS_CPU_SCALE_FACTOR 1}}
{{$PROMETHEUS_MEMORY_LIMIT_FACTOR := DefaultParam .CL2_PROMETHEUS_MEMORY_LIMIT_FACTOR 2}}
{{$PROMETHEUS_MEMORY_SCALE_FACTOR := DefaultParam .CL2_PROMETHEUS_MEMORY_SCALE_FACTOR $PROMETHEUS_MEMORY_LIMIT_FACTOR}}
{{$PROMETHEUS_NODE_SELECTOR := DefaultParam .CL2_PROMETHEUS_NODE_SELECTOR ""}}
{{$PROMETHEUS_TOLERATE_MASTER := DefaultParam .CL2_PROMETHEUS_TOLERATE_MASTER false}}
{{$PROMETHEUS_PVC_STORAGE_CLASS := DefaultParam .PROMETHEUS_PVC_STORAGE_CLASS "ssd"}}
{{$PROMETHEUS_MEMORY_REQUEST := DefaultParam .PROMETHEUS_MEMORY_REQUEST "10Gi"}}

apiVersion: monitoring.coreos.com/v1
kind: Prometheus
metadata:
  labels:
    prometheus: k8s
  name: k8s
  namespace: monitoring
spec:
  logLevel: debug
  enableAdminAPI: true
  baseImage: gcr.io/k8s-testimages/quay.io/prometheus/prometheus
  nodeSelector:
    kubernetes.io/os: linux
    {{$PROMETHEUS_NODE_SELECTOR}}
  replicas: 1
  resources:
    requests:
      cpu: {{AddInt 200 (MultiplyInt $PROMETHEUS_CPU_SCALE_FACTOR 500 (DivideInt .Nodes 1000))}}m
      {{if $PROMETHEUS_SCRAPE_KUBELETS}}
      memory: {{$PROMETHEUS_MEMORY_REQUEST}}
      {{else}}
      # Start with 2Gi and add 2Gi for each 1K nodes.
      memory: {{MultiplyInt $PROMETHEUS_MEMORY_SCALE_FACTOR (AddInt 1 (DivideInt .Nodes 1000))}}Gi
      {{end}}
    limits:
      {{if $PROMETHEUS_SCRAPE_KUBELETS}}
      memory: 10Gi
      {{else}}
      # Default: Start with 2Gi and add 2Gi for each 1K nodes.
      memory: {{MultiplyInt $PROMETHEUS_MEMORY_SCALE_FACTOR (AddInt 1 (DivideInt .Nodes 1000))}}Gi
      {{end}}
  ruleSelector:
    matchLabels:
      prometheus: k8s
  securityContext:
    fsGroup: 2000
    runAsNonRoot: true
    runAsUser: 1000
  tolerations:
  - key: "monitoring"
    operator: "Exists"
    effect: "NoSchedule"
  {{if $PROMETHEUS_TOLERATE_MASTER}}
  - key: node-role.kubernetes.io/master
    operator: Exists
    effect: NoSchedule
  - key: node-role.kubernetes.io/control-plane
    operator: Exists
    effect: NoSchedule
  {{end}}
  serviceAccountName: prometheus-k8s
  serviceMonitorNamespaceSelector: {}
  serviceMonitorSelector: {}
  podMonitorNamespaceSelector: {}
  podMonitorSelector: {}
  priorityClassName: prometheus-priorityclass
  version: v2.25.0
  retention: 7d
  {{if not $PROMETHEUS_TOLERATE_MASTER}}
  # We add node tolerations for control-plane nodes in Azure Windows test jobs which do not support Google PD
  storage:
    volumeClaimTemplate:
      spec:
        storageClassName: {{$PROMETHEUS_PVC_STORAGE_CLASS}}
        resources:
          requests:
            # Start with 10Gi, add 10Gi for each 1K nodes.
            storage: {{MultiplyInt 10 (AddInt 1 (DivideInt .Nodes 1000))}}Gi
  {{ end }}
  query:
    maxSamples: 100000000
  {{if $PROMETHEUS_SCRAPE_WINDOWS_NODES}}
  additionalScrapeConfigs:
    name: windows-scrape-configs
    key: windows-scrape-configs.yaml
  {{end}}
