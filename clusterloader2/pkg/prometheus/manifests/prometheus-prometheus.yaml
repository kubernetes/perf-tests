apiVersion: monitoring.coreos.com/v1
kind: Prometheus
metadata:
  labels:
    prometheus: k8s
  name: k8s
  namespace: monitoring
spec:
  alerting:
    alertmanagers:
    - name: alertmanager-main
      namespace: monitoring
      port: web
  baseImage: gcr.io/k8s-testimages/quay.io/prometheus/prometheus
  nodeSelector:
    beta.kubernetes.io/os: linux
  replicas: 1
  resources:
    requests:
      # Start with 2Gi and add 2Gi for each 2K nodes.
      memory: {{MultiplyInt 2 (AddInt 1 (DivideInt .Nodes 2000))}}Gi
  ruleSelector:
    matchLabels:
      prometheus: k8s
      role: alert-rules
  securityContext:
    fsGroup: 2000
    runAsNonRoot: true
    runAsUser: 1000
  serviceAccountName: prometheus-k8s
  serviceMonitorNamespaceSelector: {}
  serviceMonitorSelector: {}
  version: v2.9.2
  retention: 7d
  {{if .CortexEnabled}}
  remoteWrite:
    - url: http://35.237.38.211:9090/cortex/{{.CortexTenantId}}/api/prom/push
      queueConfig:
        # The default is 1 shard which is not enough in our set-up, causing initial samples to be
        # dropped until more shards are added. We avoid that by starting with 5 shards.
        minShards: 5
  {{end}}
  storage:
    volumeClaimTemplate:
      spec:
        storageClassName: ssd
        resources:
          requests:
            # Start with 10Gi, add 10Gi for each 1K nodes.
            storage: {{MultiplyInt 10 (AddInt 1 (DivideInt .Nodes 1000))}}Gi
