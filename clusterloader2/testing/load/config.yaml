# ASSUMPTIONS:
# - Underlying cluster should have 100+ nodes.
# - Number of nodes should be divisible by NODES_PER_NAMESPACE (default 100).
# - The number of created SVCs is half the number of created Deployments.
# - Only half of Deployments will be assigned 1-1 to existing SVCs.

#Constants
{{$NODE_MODE := DefaultParam .NODE_MODE "allnodes"}}
{{$NODES_PER_NAMESPACE := DefaultParam .NODES_PER_NAMESPACE 100}}
{{$PODS_PER_NODE := DefaultParam .PODS_PER_NODE 30}}
{{$LOAD_TEST_THROUGHPUT := DefaultParam .CL2_LOAD_TEST_THROUGHPUT 10}}
{{$DELETE_TEST_THROUGHPUT := DefaultParam .CL2_DELETE_TEST_THROUGHPUT $LOAD_TEST_THROUGHPUT}}
{{$BIG_GROUP_SIZE := DefaultParam .BIG_GROUP_SIZE 250}}
{{$MEDIUM_GROUP_SIZE := DefaultParam .MEDIUM_GROUP_SIZE 30}}
{{$SMALL_GROUP_SIZE := DefaultParam .SMALL_GROUP_SIZE 5}}
{{$SMALL_STATEFUL_SETS_PER_NAMESPACE := DefaultParam .SMALL_STATEFUL_SETS_PER_NAMESPACE 1}}
{{$MEDIUM_STATEFUL_SETS_PER_NAMESPACE := DefaultParam .MEDIUM_STATEFUL_SETS_PER_NAMESPACE 1}}
{{$ENABLE_CHAOSMONKEY := DefaultParam .ENABLE_CHAOSMONKEY false}}
{{$PROMETHEUS_SCRAPE_KUBE_PROXY := DefaultParam .PROMETHEUS_SCRAPE_KUBE_PROXY true}}
{{$ENABLE_PROMETHEUS_API_RESPONSIVENESS := DefaultParam .ENABLE_PROMETHEUS_API_RESPONSIVENESS false}}
{{$ENABLE_PVS := DefaultParam .CL2_ENABLE_PVS true}}
{{$ENABLE_NETWORKPOLICIES := DefaultParam .CL2_ENABLE_NETWORKPOLICIES false}}
{{$ENABLE_DENSITY_TEST := DefaultParam .CL2_ENABLE_DENSITY_TEST false}}
{{$ENABLE_SYSTEM_POD_METRICS:= DefaultParam .ENABLE_SYSTEM_POD_METRICS true}}
{{$ENABLE_CLUSTER_OOMS_TRACKER := DefaultParam .CL2_ENABLE_CLUSTER_OOMS_TRACKER false}}
{{$CLUSTER_OOMS_IGNORED_PROCESSES := DefaultParam .CL2_CLUSTER_OOMS_IGNORED_PROCESSES ""}}
{{$USE_SIMPLE_LATENCY_QUERY := DefaultParam .USE_SIMPLE_LATENCY_QUERY false}}
{{$ENABLE_RESTART_COUNT_CHECK := DefaultParam .ENABLE_RESTART_COUNT_CHECK false}}
{{$RESTART_COUNT_THRESHOLD_OVERRIDES:= DefaultParam .RESTART_COUNT_THRESHOLD_OVERRIDES ""}}
{{$ALLOWED_SLOW_API_CALLS := DefaultParam .CL2_ALLOWED_SLOW_API_CALLS 0}}
{{$CUSTOM_API_CALL_THRESHOLDS := DefaultParam .CUSTOM_API_CALL_THRESHOLDS ""}}
{{$ENABLE_VIOLATIONS_FOR_API_CALL_PROMETHEUS := DefaultParam .CL2_ENABLE_VIOLATIONS_FOR_API_CALL_PROMETHEUS false}}
#Variables
{{$namespaces := DivideInt .Nodes $NODES_PER_NAMESPACE}}
{{$totalPods := MultiplyInt $namespaces $NODES_PER_NAMESPACE $PODS_PER_NODE}}
{{$podsPerNamespace := DivideInt $totalPods $namespaces}}
{{$saturationTime := DivideInt $totalPods $LOAD_TEST_THROUGHPUT}}
{{$deletionTime := DivideInt $totalPods $DELETE_TEST_THROUGHPUT}}
# bigDeployments - 1/4 of namespace pods should be in big Deployments.
{{$bigDeploymentsPerNamespace := DivideInt $podsPerNamespace (MultiplyInt 4 $BIG_GROUP_SIZE)}}
# mediumDeployments - 1/4 of namespace pods should be in medium Deployments.
{{$mediumDeploymentsPerNamespace := DivideInt $podsPerNamespace (MultiplyInt 4 $MEDIUM_GROUP_SIZE)}}
# smallDeployments - 1/2 of namespace pods should be in small Deployments.
{{$smallDeploymentsPerNamespace := DivideInt $podsPerNamespace (MultiplyInt 2 $SMALL_GROUP_SIZE)}}
# Reduce the number of small and medium deployments per namespace
{{$smallDeploymentsPerNamespace := SubtractInt $smallDeploymentsPerNamespace $SMALL_STATEFUL_SETS_PER_NAMESPACE}}
{{$mediumDeploymentsPerNamespace := SubtractInt $mediumDeploymentsPerNamespace $MEDIUM_STATEFUL_SETS_PER_NAMESPACE}}

# Reduce the number of small, medium, big deployments per namespace.
{{$smallDeploymentsPerNamespace := SubtractInt $smallDeploymentsPerNamespace 1}}
{{$mediumDeploymentsPerNamespace := SubtractInt $mediumDeploymentsPerNamespace 1}}
{{$bigDeploymentsPerNamespace := SubtractInt $bigDeploymentsPerNamespace 1}}

# The minimal number of pods to be used to measure various things like
# pod-startup-latency or scheduler-throughput. The purpose of it is to avoid
# problems in small clusters where we wouldn't have enough samples (pods) to
# measure things accurately.
{{$MIN_PODS_IN_SMALL_CLUSTERS := 500}}

# BEGIN scheduler-throughput section
# TODO( https://github.com/kubernetes/perf-tests/issues/1027): Lower the number of "min-pods" once we fix the scheduler throughput measurement.
{{$totalSchedulerThroughputPods := MaxInt (MultiplyInt 2 $MIN_PODS_IN_SMALL_CLUSTERS) (MultiplyInt 2 .Nodes)}}
{{$schedulerThroughputPodsPerDeployment := .Nodes}}
{{$schedulerThroughputNamespaces := DivideInt $totalSchedulerThroughputPods $schedulerThroughputPodsPerDeployment}}
{{$schedulerThroughputThreshold := DefaultParam .CL2_SCHEDULER_THROUGHPUT_THRESHOLD 100}}
# END scheduler-throughput section

# TODO(https://github.com/kubernetes/perf-tests/issues/1024): Investigate and get rid of this section.
# BEGIN pod-startup-latency section
{{$totalLatencyPods := MaxInt $MIN_PODS_IN_SMALL_CLUSTERS .Nodes}}
{{$latencyReplicas := DivideInt $totalLatencyPods $namespaces}}
{{$podStartupLatencyThreshold := DefaultParam .CL2_POD_STARTUP_LATENCY_THRESHOLD "5s"}}
# END pod-startup-latency section

# Probe measurements shared parameter
{{$PROBE_MEASUREMENTS_CHECK_PROBES_READY_TIMEOUT := DefaultParam .CL2_PROBE_MEASUREMENTS_CHECK_PROBES_READY_TIMEOUT "5m"}}

# Command to be executed
{{$EXEC_COMMAND := DefaultParam .CL2_EXEC_COMMAND nil}}

name: load
namespace:
  number: {{AddInt $namespaces $schedulerThroughputNamespaces}}
tuningSets:
- name: Sequence
  parallelismLimitedLoad:
    parallelismLimit: 1
# Dedicated tuningSet for SchedulerThroughput phases that results in fully
# parallel creation of deployments.
- name: SchedulerThroughputParallel
  parallelismLimitedLoad:
    parallelismLimit: {{$schedulerThroughputNamespaces}}
# TODO(https://github.com/kubernetes/perf-tests/issues/1024): This TuningSet is used only for pod-startup-latency, get rid of it
- name: Uniform5qps
  qpsLoad:
    qps: 5
- name: RandomizedSaturationTimeLimited
  RandomizedTimeLimitedLoad:
    timeLimit: {{$saturationTime}}s
- name: RandomizedScalingTimeLimited
  RandomizedTimeLimitedLoad:
    # The expected number of created/deleted pods is totalPods/4 when scaling,
    # as each RS changes its size from X to a uniform random value in [X/2, 3X/2].
    # To match 10 [pods/s] requirement, we need to divide saturationTime by 4.
    timeLimit: {{DivideInt $saturationTime 4}}s
- name: RandomizedDeletionTimeLimited
  RandomizedTimeLimitedLoad:
    timeLimit: {{$deletionTime}}s
{{if $ENABLE_CHAOSMONKEY}}
chaosMonkey:
  nodeFailure:
    failureRate: 0.01
    interval: 5m
    jitterFactor: 2.0
    simulatedDowntime: 10m
{{end}}
steps:
- name: Starting measurements
  measurements:
  - Identifier: APIResponsivenessPrometheus
    Method: APIResponsivenessPrometheus
    Params:
      action: start
  - Identifier: APIResponsivenessPrometheusSimple
    Method: APIResponsivenessPrometheus
    Params:
      action: start
  - Identifier: CreatePhasePodStartupLatency
    Method: PodStartupLatency
    Params:
      action: start
      labelSelector: group = load
      threshold: 1h # TODO(https://github.com/kubernetes/perf-tests/issues/1024): Ideally, this should be 5s
  - Identifier: InClusterNetworkLatency
    Method: InClusterNetworkLatency
    Params:
      action: start
      checkProbesReadyTimeout: {{$PROBE_MEASUREMENTS_CHECK_PROBES_READY_TIMEOUT}}
      replicasPerProbe: {{AddInt 2 (DivideInt .Nodes 100)}}
  - Identifier: SLOMeasurement
    Method: SLOMeasurement
    Params:
      action: start
      checkProbesReadyTimeout: {{$PROBE_MEASUREMENTS_CHECK_PROBES_READY_TIMEOUT}}
      replicasPerProbe: {{AddInt 2 (DivideInt .Nodes 100)}}
  {{if $PROMETHEUS_SCRAPE_KUBE_PROXY}}
  - Identifier: NetworkProgrammingLatency
    Method: NetworkProgrammingLatency
    Params:
      action: start
  {{end}}
  - Identifier: TestMetrics
    Method: TestMetrics
    Params:
      action: start
      nodeMode: {{$NODE_MODE}}
      systemPodMetricsEnabled: {{$ENABLE_SYSTEM_POD_METRICS}}
      clusterOOMsTrackerEnabled: {{$ENABLE_CLUSTER_OOMS_TRACKER}}
      clusterOOMsIgnoredProcesses: {{$CLUSTER_OOMS_IGNORED_PROCESSES}}
      restartCountThresholdOverrides: {{YamlQuote $RESTART_COUNT_THRESHOLD_OVERRIDES 4}}
      enableRestartCountCheck: {{$ENABLE_RESTART_COUNT_CHECK}}

- name: Creating SVCs
  phases:
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: {{DivideInt (AddInt $bigDeploymentsPerNamespace 1) 2}}
    tuningSet: Sequence
    objectBundle:
    - basename: big-service
      objectTemplatePath: service.yaml
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: {{DivideInt (AddInt $mediumDeploymentsPerNamespace 1) 2}}
    tuningSet: Sequence
    objectBundle:
    - basename: medium-service
      objectTemplatePath: service.yaml
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: {{DivideInt (AddInt $smallDeploymentsPerNamespace 1) 2}}
    tuningSet: Sequence
    objectBundle:
    - basename: small-service
      objectTemplatePath: service.yaml

- name: Creating PriorityClass for DaemonSets
  phases:
  - replicasPerNamespace: 1
    tuningSet: Sequence
    objectBundle:
      - basename: daemonset-priorityclass
        objectTemplatePath: daemonset-priorityclass.yaml

- name: Starting measurement for waiting for pods
  measurements:
  - Method: WaitForControlledPodsRunning
    Instances:
    - Identifier: WaitForRunningDeployments
      Params:
        apiVersion: apps/v1
        kind: Deployment
    - Identifier: WaitForRunningStatefulSets
      Params:
        apiVersion: apps/v1
        kind: StatefulSet
    - Identifier: WaitForRunningDaemonSets
      Params:
        apiVersion: apps/v1
        kind: DaemonSet
    - Identifier: WaitForRunningJobs
      Params:
        apiVersion: batch/v1
        kind: Job
    Params:
      action: start
      labelSelector: group = load
      operationTimeout: 15m

- name: Creating objects
  phases:
  - namespaceRange:
      min: 1
      max: 1
    replicasPerNamespace: 1
    tuningSet: RandomizedSaturationTimeLimited
    objectBundle:
    - basename: daemonset
      objectTemplatePath: daemonset.yaml
      templateFillMap:
        Image: k8s.gcr.io/pause:3.0
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: {{$bigDeploymentsPerNamespace}}
    tuningSet: RandomizedSaturationTimeLimited
    objectBundle:
    - basename: big-deployment
      objectTemplatePath: configmap.yaml
    - basename: big-deployment
      objectTemplatePath: secret.yaml
    {{if $ENABLE_NETWORKPOLICIES}}
    - basename: big-deployment
      objectTemplatePath: networkpolicy.yaml
    {{end}}
    - basename: big-deployment
      objectTemplatePath: deployment.yaml
      templateFillMap:
        ReplicasMin: {{$BIG_GROUP_SIZE}}
        ReplicasMax: {{$BIG_GROUP_SIZE}}
        SvcName: big-service
{{if $ENABLE_DENSITY_TEST}}
        CpuRequest: 5m
{{end}}
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: {{$mediumDeploymentsPerNamespace}}
    tuningSet: RandomizedSaturationTimeLimited
    objectBundle:
    - basename: medium-deployment
      objectTemplatePath: configmap.yaml
    - basename: medium-deployment
      objectTemplatePath: secret.yaml
    {{if $ENABLE_NETWORKPOLICIES}}
    - basename: medium-deployment
      objectTemplatePath: networkpolicy.yaml
    {{end}}
    - basename: medium-deployment
      objectTemplatePath: deployment.yaml
      templateFillMap:
        ReplicasMin: {{$MEDIUM_GROUP_SIZE}}
        ReplicasMax: {{$MEDIUM_GROUP_SIZE}}
        SvcName: medium-service
{{if $ENABLE_DENSITY_TEST}}
        CpuRequest: 5m
{{end}}
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: {{$smallDeploymentsPerNamespace}}
    tuningSet: RandomizedSaturationTimeLimited
    objectBundle:
    - basename: small-deployment
      objectTemplatePath: configmap.yaml
    - basename: small-deployment
      objectTemplatePath: secret.yaml
    {{if $ENABLE_NETWORKPOLICIES}}
    - basename: small-deployment
      objectTemplatePath: networkpolicy.yaml
    {{end}}
    - basename: small-deployment
      objectTemplatePath: deployment.yaml
      templateFillMap:
        ReplicasMin: {{$SMALL_GROUP_SIZE}}
        ReplicasMax: {{$SMALL_GROUP_SIZE}}
        SvcName: small-service
{{if $ENABLE_DENSITY_TEST}}
        CpuRequest: 5m
{{end}}
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: {{$SMALL_STATEFUL_SETS_PER_NAMESPACE}}
    tuningSet: RandomizedSaturationTimeLimited
    objectBundle:
      - basename: small-statefulset
        objectTemplatePath: statefulset_service.yaml
      - basename: small-statefulset
        objectTemplatePath: statefulset.yaml
        templateFillMap:
          ReplicasMin: {{$SMALL_GROUP_SIZE}}
          ReplicasMax: {{$SMALL_GROUP_SIZE}}
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: {{$MEDIUM_STATEFUL_SETS_PER_NAMESPACE}}
    tuningSet: RandomizedSaturationTimeLimited
    objectBundle:
      - basename: medium-statefulset
        objectTemplatePath: statefulset_service.yaml
      - basename: medium-statefulset
        objectTemplatePath: statefulset.yaml
        templateFillMap:
          ReplicasMin: {{$MEDIUM_GROUP_SIZE}}
          ReplicasMax: {{$MEDIUM_GROUP_SIZE}}
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: 1
    tuningSet: RandomizedSaturationTimeLimited
    objectBundle:
      - basename: small-job
        objectTemplatePath: job.yaml
        templateFillMap:
          ReplicasMin: {{$SMALL_GROUP_SIZE}}
          ReplicasMax: {{$SMALL_GROUP_SIZE}}
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: 1
    tuningSet: RandomizedSaturationTimeLimited
    objectBundle:
      - basename: medium-job
        objectTemplatePath: job.yaml
        templateFillMap:
          ReplicasMin: {{$MEDIUM_GROUP_SIZE}}
          ReplicasMax: {{$MEDIUM_GROUP_SIZE}}
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: 1
    tuningSet: RandomizedSaturationTimeLimited
    objectBundle:
      - basename: big-job
        objectTemplatePath: job.yaml
        templateFillMap:
          ReplicasMin: {{$BIG_GROUP_SIZE}}
          ReplicasMax: {{$BIG_GROUP_SIZE}}

- name: Waiting for pods to be running
  measurements:
  - Method: WaitForControlledPodsRunning
    Instances:
     - Identifier: WaitForRunningDeployments
     - Identifier: WaitForRunningStatefulSets
     - Identifier: WaitForRunningDaemonSets
     - Identifier: WaitForRunningJobs
    Params:
      action: gather

{{if $EXEC_COMMAND}}
- name: Exec command
  measurements:
  - Identifier: ExecCommand
    Method: Exec
    Params:
      command:
      {{range $EXEC_COMMAND}}
      - {{.}}
      {{end}}
{{end}}

{{if $ENABLE_DENSITY_TEST}}
# BEGIN scheduler throughput
- name: Creating scheduler throughput measurements
  measurements:
  - Identifier: HighThroughputPodStartupLatency
    Method: PodStartupLatency
    Params:
      action: start
      labelSelector: group = scheduler-throughput
      threshold: 1h # TODO(https://github.com/kubernetes/perf-tests/issues/1024): Ideally, this should be 5s
  - Identifier: WaitForSchedulerThroughputDeployments
    Method: WaitForControlledPodsRunning
    Params:
      action: start
      apiVersion: apps/v1
      kind: Deployment
      labelSelector: group = scheduler-throughput
      # The operation timeout shouldn't be less than 20m to make sure that ~10m node
      # failure won't fail the test. See https://github.com/kubernetes/kubernetes/issues/73461#issuecomment-467338711
      operationTimeout: 20m
  - Identifier: SchedulingThroughput
    Method: SchedulingThroughput
    Params:
      action: start
      labelSelector: group = scheduler-throughput
      measurmentInterval: 1s
- name: Creating scheduler throughput pods
  phases:
  - namespaceRange:
      min: {{AddInt $namespaces 1}}
      max: {{AddInt $namespaces $schedulerThroughputNamespaces}}
    replicasPerNamespace: 1
    tuningSet: SchedulerThroughputParallel
    objectBundle:
    - basename: scheduler-throughput-deployment
      objectTemplatePath: simple-deployment.yaml
      templateFillMap:
        Replicas: {{$schedulerThroughputPodsPerDeployment}}
        Group: scheduler-throughput
        CpuRequest: 1m
        MemoryRequest: 10M
- name: Waiting for scheduler throughput pods to be created
  measurements:
  - Identifier: WaitForSchedulerThroughputDeployments
    Method: WaitForControlledPodsRunning
    Params:
      action: gather
- name: Collecting scheduler throughput measurements
  measurements:
  - Identifier: HighThroughputPodStartupLatency
    Method: PodStartupLatency
    Params:
      action: gather
  - Identifier: SchedulingThroughput
    Method: SchedulingThroughput
    Params:
      action: gather
      enableViolations: true
      threshold: {{$schedulerThroughputThreshold}}
- name: Deleting scheduler throughput pods
  phases:
  - namespaceRange:
      min: {{AddInt $namespaces 1}}
      max: {{AddInt $namespaces $schedulerThroughputNamespaces}}
    replicasPerNamespace: 0
    tuningSet: SchedulerThroughputParallel
    objectBundle:
    - basename: scheduler-throughput-deployment
      objectTemplatePath: simple-deployment.yaml
- name: Waiting for scheduler throughput pods to be deleted
  measurements:
  - Identifier: WaitForSchedulerThroughputDeployments
    Method: WaitForControlledPodsRunning
    Params:
      action: gather
# END scheduler throughput

# TODO(https://github.com/kubernetes/perf-tests/issues/1024): Ideally, we wouldn't need this section.
# BEGIN pod-startup-latency
- name: Starting latency pod measurements
  measurements:
  - Identifier: PodStartupLatency
    Method: PodStartupLatency
    Params:
      action: start
      labelSelector: group = latency
      threshold: {{$podStartupLatencyThreshold}}
  - Identifier: WaitForRunningLatencyDeployments
    Method: WaitForControlledPodsRunning
    Params:
      action: start
      apiVersion: apps/v1
      kind: Deployment
      labelSelector: group = latency
      operationTimeout: 15m
- name: Creating latency pods
  phases:
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: {{$latencyReplicas}}
    tuningSet: Uniform5qps
    objectBundle:
    - basename: latency-deployment
      objectTemplatePath: simple-deployment.yaml
      templateFillMap:
        Replicas: 1
        Group: latency
        # CPU and memory requests are calculated for 1-core 4GB node.
        # Increasing allocation of both memory and cpu by 10% decreases the
        # value of priority function in scheduler by one point.
        # This results in decreased probability of choosing the same node again.
        # TODO(https://github.com/kubernetes/perf-tests/issues/1024): See whether we can get rid of this
        CpuRequest: 100m
        MemoryRequest: 350M
- name: Waiting for latency pods to be running
  measurements:
  - Identifier: WaitForRunningLatencyDeployments
    Method: WaitForControlledPodsRunning
    Params:
      action: gather
- name: Deleting latency pods
  phases:
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: 0
    tuningSet: Uniform5qps
    objectBundle:
    - basename: latency-deployment
      objectTemplatePath: simple-deployment.yaml
- name: Waiting for latency pods to be deleted
  measurements:
  - Identifier: WaitForRunningLatencyDeployments
    Method: WaitForControlledPodsRunning
    Params:
      action: gather
- name: Collecting pod startup latency
  measurements:
  - Identifier: PodStartupLatency
    Method: PodStartupLatency
    Params:
      action: gather
# END pod-startup-latency
{{end}}

- name: Scaling and updating objects
  phases:
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: {{$bigDeploymentsPerNamespace}}
    tuningSet: RandomizedScalingTimeLimited
    objectBundle:
    - basename: big-deployment
      objectTemplatePath: deployment.yaml
      templateFillMap:
        ReplicasMin: {{MultiplyInt $BIG_GROUP_SIZE 0.5}}
        ReplicasMax: {{MultiplyInt $BIG_GROUP_SIZE 1.5}}
        SvcName: big-service
{{if $ENABLE_DENSITY_TEST}}
        CpuRequest: 5m
{{end}}
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: {{$mediumDeploymentsPerNamespace}}
    tuningSet: RandomizedScalingTimeLimited
    objectBundle:
    - basename: medium-deployment
      objectTemplatePath: deployment.yaml
      templateFillMap:
        ReplicasMin: {{MultiplyInt $MEDIUM_GROUP_SIZE 0.5}}
        ReplicasMax: {{MultiplyInt $MEDIUM_GROUP_SIZE 1.5}}
        SvcName: medium-service
{{if $ENABLE_DENSITY_TEST}}
        CpuRequest: 5m
{{end}}
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: {{$smallDeploymentsPerNamespace}}
    tuningSet: RandomizedScalingTimeLimited
    objectBundle:
    - basename: small-deployment
      objectTemplatePath: deployment.yaml
      templateFillMap:
        ReplicasMin: {{MultiplyInt $SMALL_GROUP_SIZE 0.5}}
        ReplicasMax: {{MultiplyInt $SMALL_GROUP_SIZE 1.5}}
        SvcName: small-service
{{if $ENABLE_DENSITY_TEST}}
        CpuRequest: 5m
{{end}}
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: {{$SMALL_STATEFUL_SETS_PER_NAMESPACE}}
    tuningSet: RandomizedScalingTimeLimited
    objectBundle:
      - basename: small-statefulset
        objectTemplatePath: statefulset.yaml
        templateFillMap:
          ReplicasMin: {{MultiplyInt $SMALL_GROUP_SIZE 0.5}}
          ReplicasMax: {{MultiplyInt $SMALL_GROUP_SIZE 1.5}}
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: {{$MEDIUM_STATEFUL_SETS_PER_NAMESPACE}}
    tuningSet: RandomizedScalingTimeLimited
    objectBundle:
      - basename: medium-statefulset
        objectTemplatePath: statefulset.yaml
        templateFillMap:
          ReplicasMin: {{MultiplyInt $MEDIUM_GROUP_SIZE 0.5}}
          ReplicasMax: {{MultiplyInt $MEDIUM_GROUP_SIZE 1.5}}
  - namespaceRange:
      min: 1
      max: 1
    replicasPerNamespace: 1
    tuningSet: RandomizedScalingTimeLimited
    objectBundle:
      - basename: daemonset
        objectTemplatePath: daemonset.yaml
        templateFillMap:
          Image: k8s.gcr.io/pause:3.1
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: 1
    tuningSet: RandomizedScalingTimeLimited
    objectBundle:
      - basename: small-job
        objectTemplatePath: job.yaml
        templateFillMap:
          ReplicasMin: {{MultiplyInt $SMALL_GROUP_SIZE 0.5}}
          ReplicasMax: {{MultiplyInt $SMALL_GROUP_SIZE 1.5}}
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: 1
    tuningSet: RandomizedScalingTimeLimited
    objectBundle:
      - basename: medium-job
        objectTemplatePath: job.yaml
        templateFillMap:
          ReplicasMin: {{MultiplyInt $MEDIUM_GROUP_SIZE 0.5}}
          ReplicasMax: {{MultiplyInt $MEDIUM_GROUP_SIZE 1.5}}
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: 1
    tuningSet: RandomizedScalingTimeLimited
    objectBundle:
      - basename: big-job
        objectTemplatePath: job.yaml
        templateFillMap:
          ReplicasMin: {{MultiplyInt $BIG_GROUP_SIZE 0.5}}
          ReplicasMax: {{MultiplyInt $BIG_GROUP_SIZE 1.5}}

- name: Waiting for objects to become scaled
  measurements:
  - Method: WaitForControlledPodsRunning
    Instances:
    - Identifier: WaitForRunningDeployments
    - Identifier: WaitForRunningStatefulSets
    - Identifier: WaitForRunningDaemonSets
    - Identifier: WaitForRunningJobs
    Params:
      action: gather

- name: Deleting objects
  phases:
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: 0
    tuningSet: RandomizedDeletionTimeLimited
    objectBundle:
    - basename: big-deployment
      objectTemplatePath: deployment.yaml
    - basename: big-deployment
      objectTemplatePath: configmap.yaml
    - basename: big-deployment
      objectTemplatePath: secret.yaml
    {{if $ENABLE_NETWORKPOLICIES}}
    - basename: big-deployment
      objectTemplatePath: networkpolicy.yaml
    {{end}}
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: 0
    tuningSet: RandomizedDeletionTimeLimited
    objectBundle:
    - basename: medium-deployment
      objectTemplatePath: deployment.yaml
    - basename: medium-deployment
      objectTemplatePath: configmap.yaml
    - basename: medium-deployment
      objectTemplatePath: secret.yaml
    {{if $ENABLE_NETWORKPOLICIES}}
    - basename: medium-deployment
      objectTemplatePath: networkpolicy.yaml
    {{end}}
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: 0
    tuningSet: RandomizedDeletionTimeLimited
    objectBundle:
    - basename: small-deployment
      objectTemplatePath: deployment.yaml
    - basename: small-deployment
      objectTemplatePath: configmap.yaml
    - basename: small-deployment
      objectTemplatePath: secret.yaml
    {{if $ENABLE_NETWORKPOLICIES}}
    - basename: small-deployment
      objectTemplatePath: networkpolicy.yaml
    {{end}}
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: 0
    tuningSet: RandomizedDeletionTimeLimited
    objectBundle:
      - basename: small-statefulset
        objectTemplatePath: statefulset.yaml
      - basename: small-statefulset
        objectTemplatePath: statefulset_service.yaml
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: 0
    tuningSet: RandomizedDeletionTimeLimited
    objectBundle:
      - basename: medium-statefulset
        objectTemplatePath: statefulset.yaml
      - basename: medium-statefulset
        objectTemplatePath: statefulset_service.yaml
  - namespaceRange:
      min: 1
      max: 1
    replicasPerNamespace: 0
    tuningSet: RandomizedDeletionTimeLimited
    objectBundle:
      - basename: daemonset
        objectTemplatePath: daemonset.yaml
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: 0
    tuningSet: RandomizedDeletionTimeLimited
    objectBundle:
      - basename: small-job
        objectTemplatePath: job.yaml
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: 0
    tuningSet: RandomizedDeletionTimeLimited
    objectBundle:
      - basename: medium-job
        objectTemplatePath: job.yaml
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: 0
    tuningSet: RandomizedDeletionTimeLimited
    objectBundle:
      - basename: big-job
        objectTemplatePath: job.yaml
  # If both StatefulSets and PVs were enabled we need to delete PVs manually.
  {{if $ENABLE_PVS}}
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: 0
    tuningSet: RandomizedDeletionTimeLimited
    objectBundle:
      {{range $ssIndex := Loop $SMALL_STATEFUL_SETS_PER_NAMESPACE}}
      - basename: pv-small-statefulset-{{$ssIndex}}
        objectTemplatePath: pvc.yaml
        listUnknownObjectOptions:
          labelSelector:
            matchLabels:
              name: small-statefulset-{{$ssIndex}}
      {{end}}
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: 0
    tuningSet: RandomizedDeletionTimeLimited
    objectBundle:
      {{range $ssIndex := Loop $MEDIUM_STATEFUL_SETS_PER_NAMESPACE}}
      - basename: pv-medium-statefulset-{{$ssIndex}}
        objectTemplatePath: pvc.yaml
        listUnknownObjectOptions:
          labelSelector:
            matchLabels:
              name: medium-statefulset-{{$ssIndex}}
      {{end}}
  {{end}}

- name: Waiting for pods to be deleted
  measurements:
  - Method: WaitForControlledPodsRunning
    Instances:
     - Identifier: WaitForRunningDeployments
     - Identifier: WaitForRunningStatefulSets
     - Identifier: WaitForRunningDaemonSets
     - Identifier: WaitForRunningJobs
    Params:
      action: gather
  {{if $ENABLE_PVS}}
  - Identifier: WaitForPVCsToBeDeleted
    Method: WaitForBoundPVCs
    Params:
      desiredPVCCount: 0
      labelSelector: group = load
      timeout: 15m
  {{end}}

- name: Deleting PriorityClass for DaemonSets
  phases:
    - replicasPerNamespace: 0
      tuningSet: Sequence
      objectBundle:
        - basename: daemonset-priorityclass
          objectTemplatePath: daemonset-priorityclass.yaml

- name: Deleting SVCs
  phases:
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: 0
    tuningSet: Sequence
    objectBundle:
    - basename: big-service
      objectTemplatePath: service.yaml
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: 0
    tuningSet: Sequence
    objectBundle:
    - basename: medium-service
      objectTemplatePath: service.yaml
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: 0
    tuningSet: Sequence
    objectBundle:
    - basename: small-service
      objectTemplatePath: service.yaml

- name: Collecting measurements
  measurements:
  - Identifier: APIResponsivenessPrometheusSimple
    Method: APIResponsivenessPrometheus
    Params:
      action: gather
      enableViolations: true
      useSimpleLatencyQuery: true
      summaryName: APIResponsivenessPrometheus_simple
      allowedSlowCalls: {{$ALLOWED_SLOW_API_CALLS}}
  {{if not $USE_SIMPLE_LATENCY_QUERY}}
  - Identifier: APIResponsivenessPrometheus
    Method: APIResponsivenessPrometheus
    Params:
      action: gather
      enableViolations: {{$ENABLE_VIOLATIONS_FOR_API_CALL_PROMETHEUS}}
      allowedSlowCalls: {{$ALLOWED_SLOW_API_CALLS}}
      customThresholds: {{YamlQuote $CUSTOM_API_CALL_THRESHOLDS 4}}
  {{end}}
  - Identifier: CreatePhasePodStartupLatency
    Method: PodStartupLatency
    Params:
      action: gather
  - Identifier: InClusterNetworkLatency
    Method: InClusterNetworkLatency
    Params:
      action: gather
  - Identifier: SLOMeasurement
    Method: SLOMeasurement
    Params:
      action: gather
  {{if $PROMETHEUS_SCRAPE_KUBE_PROXY}}
  - Identifier: NetworkProgrammingLatency
    Method: NetworkProgrammingLatency
    Params:
      action: gather
  {{end}}
  - Identifier: TestMetrics
    Method: TestMetrics
    Params:
      action: gather
      systemPodMetricsEnabled: {{$ENABLE_SYSTEM_POD_METRICS}}
      clusterOOMsTrackerEnabled: {{$ENABLE_CLUSTER_OOMS_TRACKER}}
      restartCountThresholdOverrides: {{YamlQuote $RESTART_COUNT_THRESHOLD_OVERRIDES 4}}
      enableRestartCountCheck: {{$ENABLE_RESTART_COUNT_CHECK}}
