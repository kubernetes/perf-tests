# ASSUMPTIONS:
# - Underlying cluster should have 100+ nodes.
# - Number of nodes should be divisible by NODES_PER_NAMESPACE (default 100).
# - The number of created SVCs is half the number of created Deployments.
# - Only half of Deployments will be assigned 1-1 to existing SVCs.

#Constants
# Cater for the case where the number of nodes is less than nodes per namespace. See https://github.com/kubernetes/perf-tests/issues/887
{{$NODES_PER_NAMESPACE := MinInt .Nodes (DefaultParam .NODES_PER_NAMESPACE 100)}}
# See https://github.com/kubernetes/perf-tests/pull/1667#issuecomment-769642266
{{$IS_SMALL_CLUSTER := lt .Nodes 100}}
{{$PODS_PER_NODE := DefaultParam .PODS_PER_NODE 30}}
{{$LOAD_TEST_THROUGHPUT := DefaultParam .CL2_LOAD_TEST_THROUGHPUT 10}}
{{$DELETE_TEST_THROUGHPUT := DefaultParam .CL2_DELETE_TEST_THROUGHPUT $LOAD_TEST_THROUGHPUT}}
{{$BIG_GROUP_SIZE := DefaultParam .BIG_GROUP_SIZE 250}}
{{$MEDIUM_GROUP_SIZE := DefaultParam .MEDIUM_GROUP_SIZE 30}}
{{$SMALL_GROUP_SIZE := DefaultParam .SMALL_GROUP_SIZE 5}}
{{$SMALL_STATEFUL_SETS_PER_NAMESPACE := DefaultParam .SMALL_STATEFUL_SETS_PER_NAMESPACE 1}}
{{$MEDIUM_STATEFUL_SETS_PER_NAMESPACE := DefaultParam .MEDIUM_STATEFUL_SETS_PER_NAMESPACE 1}}
{{$ENABLE_CHAOSMONKEY := DefaultParam .ENABLE_CHAOSMONKEY false}}
{{$CHECK_IF_PODS_ARE_UPDATED := DefaultParam .CL2_CHECK_IF_PODS_ARE_UPDATED true}}
{{$PROMETHEUS_SCRAPE_KUBE_PROXY := DefaultParam .PROMETHEUS_SCRAPE_KUBE_PROXY true}}
{{$ENABLE_PVS := DefaultParam .CL2_ENABLE_PVS true}}
{{$DISABLE_DAEMONSETS := DefaultParam .CL2_DISABLE_DAEMONSETS false}}
{{$ENABLE_NETWORKPOLICIES := DefaultParam .CL2_ENABLE_NETWORKPOLICIES false}}
{{$ENABLE_NODE_LOCAL_DNS_LATENCY := DefaultParam .CL2_ENABLE_NODE_LOCAL_DNS_LATENCY false}}
{{$NODE_LOCAL_DNS_LATENCY_THRESHOLD := DefaultParam .CL2_NODE_LOCAL_DNS_LATENCY_THRESHOLD "5s"}}
{{$ENABLE_DNSTESTS := DefaultParam .CL2_ENABLE_DNSTESTS false}}
{{$TURN_OFF_LOGGING_TO_FILE_FOR_PROBES := DefaultParam .CL2_TURN_OFF_LOGGING_TO_FILE_FOR_PROBES false}}
{{$ENABLE_SYSTEM_POD_METRICS:= DefaultParam .ENABLE_SYSTEM_POD_METRICS true}}
{{$ENABLE_CLUSTER_OOMS_TRACKER := DefaultParam .CL2_ENABLE_CLUSTER_OOMS_TRACKER true}}
{{$CLUSTER_OOMS_IGNORED_PROCESSES := DefaultParam .CL2_CLUSTER_OOMS_IGNORED_PROCESSES ""}}
{{$USE_SIMPLE_LATENCY_QUERY := DefaultParam .USE_SIMPLE_LATENCY_QUERY false}}
{{$ENABLE_RESTART_COUNT_CHECK := DefaultParam .ENABLE_RESTART_COUNT_CHECK true}}
{{$RESTART_COUNT_THRESHOLD_OVERRIDES:= DefaultParam .RESTART_COUNT_THRESHOLD_OVERRIDES ""}}
{{$ALLOWED_SLOW_API_CALLS := DefaultParam .CL2_ALLOWED_SLOW_API_CALLS 0}}
{{$CUSTOM_API_CALL_THRESHOLDS := DefaultParam .CUSTOM_API_CALL_THRESHOLDS ""}}
{{$ENABLE_VIOLATIONS_FOR_API_CALL_PROMETHEUS := DefaultParam .CL2_ENABLE_VIOLATIONS_FOR_API_CALL_PROMETHEUS false}}
{{$ENABLE_VIOLATIONS_FOR_API_CALL_PROMETHEUS_SIMPLE := DefaultParam .CL2_ENABLE_VIOLATIONS_FOR_API_CALL_PROMETHEUS_SIMPLE true}}
{{$ENABLE_API_AVAILABILITY_MEASUREMENT := DefaultParam .CL2_ENABLE_API_AVAILABILITY_MEASUREMENT false}}
#Variables
{{$namespaces := DivideInt .Nodes $NODES_PER_NAMESPACE}}
{{$totalPods := MultiplyInt $namespaces $NODES_PER_NAMESPACE $PODS_PER_NODE}}
{{$podsPerNamespace := DivideInt $totalPods $namespaces}}
{{$saturationTime := DivideInt $totalPods $LOAD_TEST_THROUGHPUT}}
{{$deletionTime := DivideInt $totalPods $DELETE_TEST_THROUGHPUT}}
# bigDeployments - 1/4 of namespace pods should be in big Deployments.
{{$bigDeploymentsPerNamespace := DivideInt $podsPerNamespace (MultiplyInt 4 $BIG_GROUP_SIZE)}}
# mediumDeployments - 1/4 of namespace pods should be in medium Deployments.
{{$mediumDeploymentsPerNamespace := DivideInt $podsPerNamespace (MultiplyInt 4 $MEDIUM_GROUP_SIZE)}}
# smallDeployments - 1/2 of namespace pods should be in small Deployments.
{{$smallDeploymentsPerNamespace := DivideInt $podsPerNamespace (MultiplyInt 2 $SMALL_GROUP_SIZE)}}

# Stateful sets are enabled. Reduce the number of small and medium deployments per namespace
# See https://github.com/kubernetes/perf-tests/issues/1036#issuecomment-607631768
# Ensure non zero or negative after subtraction.
{{$smallDeploymentsPerNamespace := MaxInt 0 (SubtractInt $smallDeploymentsPerNamespace $SMALL_STATEFUL_SETS_PER_NAMESPACE)}}
{{$mediumDeploymentsPerNamespace := MaxInt 0 (SubtractInt $mediumDeploymentsPerNamespace $MEDIUM_STATEFUL_SETS_PER_NAMESPACE)}}

# Jobs are enabled. Reduce the number of small, medium, big deployments per namespace.
# Ensure non zero or negative after subtraction.
{{$smallDeploymentsPerNamespace := MaxInt 0 (SubtractInt $smallDeploymentsPerNamespace 1)}}
{{$mediumDeploymentsPerNamespace := MaxInt 0 (SubtractInt $mediumDeploymentsPerNamespace 1)}}
{{$bigDeploymentsPerNamespace := MaxInt 0 (SubtractInt $bigDeploymentsPerNamespace 1)}}

# Disable big jobs on small clusters.
{{$bigJobsPerNamespace := IfThenElse $IS_SMALL_CLUSTER 0 1}}

# The minimal number of pods to be used to measure various things like
# pod-startup-latency or scheduler-throughput. The purpose of it is to avoid
# problems in small clusters where we wouldn't have enough samples (pods) to
# measure things accurately.
{{$MIN_PODS_IN_SMALL_CLUSTERS := 500}}

# BEGIN scheduler-throughput section
# TODO( https://github.com/kubernetes/perf-tests/issues/1027): Lower the number of "min-pods" once we fix the scheduler throughput measurement.
{{$totalSchedulerThroughputPods := MaxInt (MultiplyInt 2 $MIN_PODS_IN_SMALL_CLUSTERS) (MultiplyInt 2 .Nodes)}}
{{$schedulerThroughputPodsPerDeployment := .Nodes}}
{{$schedulerThroughputNamespaces := DivideInt $totalSchedulerThroughputPods $schedulerThroughputPodsPerDeployment}}
{{$schedulerThroughputThreshold := DefaultParam .CL2_SCHEDULER_THROUGHPUT_THRESHOLD 100}}
{{$ENABLE_HUGE_SERVICES := DefaultParam .CL2_ENABLE_HUGE_SERVICES false}}
# END scheduler-throughput section

# Set schedulerThroughputNamespaces to 0 on small clusters otherwise it will result
# in an unnecessary number of namespaces.
{{$schedulerThroughputNamespaces := IfThenElse $IS_SMALL_CLUSTER 0 $schedulerThroughputNamespaces}}

# Probe measurements shared parameter
{{$PROBE_MEASUREMENTS_CHECK_PROBES_READY_TIMEOUT := DefaultParam .CL2_PROBE_MEASUREMENTS_CHECK_PROBES_READY_TIMEOUT "15m"}}

# Command to be executed
{{$EXEC_COMMAND := DefaultParam .CL2_EXEC_COMMAND nil}}
{{$EXIT_AFTER_EXEC := DefaultParam .CL2_EXIT_AFTER_EXEC false}}
{{$SLEEP_AFTER_EXEC_DURATION := DefaultParam .CL2_SLEEP_AFTER_EXEC_DURATION "0s"}}

name: load
namespace:
  number: {{AddInt $namespaces $schedulerThroughputNamespaces}}
tuningSets:
- name: Sequence
  parallelismLimitedLoad:
    parallelismLimit: 1
# Dedicated tuningSet for SchedulerThroughput phases that results in fully
# parallel creation of deployments.
- name: SchedulerThroughputParallel
  parallelismLimitedLoad:
    parallelismLimit: {{$schedulerThroughputNamespaces}}
# TODO(https://github.com/kubernetes/perf-tests/issues/1024): This TuningSet is used only for pod-startup-latency, get rid of it
- name: Uniform5qps
  qpsLoad:
    qps: 5
- name: RandomizedSaturationTimeLimited
  RandomizedTimeLimitedLoad:
    timeLimit: {{$saturationTime}}s
- name: RandomizedScalingTimeLimited
  RandomizedTimeLimitedLoad:
    # The expected number of created/deleted pods is totalPods/4 when scaling,
    # as each RS changes its size from X to a uniform random value in [X/2, 3X/2].
    # To match 10 [pods/s] requirement, we need to divide saturationTime by 4.
    timeLimit: {{DivideInt $saturationTime 4}}s
- name: RandomizedDeletionTimeLimited
  RandomizedTimeLimitedLoad:
    timeLimit: {{$deletionTime}}s
{{if $ENABLE_CHAOSMONKEY}}
chaosMonkey:
  nodeFailure:
    failureRate: 0.01
    interval: 5m
    jitterFactor: 2.0
    simulatedDowntime: 10m
{{end}}
steps:
- name: Starting measurements
  measurements:
  - Identifier: APIResponsivenessPrometheus
    Method: APIResponsivenessPrometheus
    Params:
      action: start
  - Identifier: APIResponsivenessPrometheusSimple
    Method: APIResponsivenessPrometheus
    Params:
      action: start
  - Identifier: CreatePhasePodStartupLatency
    Method: PodStartupLatency
    Params:
      action: start
      labelSelector: group = load
      threshold: 1h # TODO(https://github.com/kubernetes/perf-tests/issues/1024): Ideally, this should be 5s
  - Identifier: InClusterNetworkLatency
    Method: InClusterNetworkLatency
    Params:
      action: start
      checkProbesReadyTimeout: {{$PROBE_MEASUREMENTS_CHECK_PROBES_READY_TIMEOUT}}
      replicasPerProbe: {{AddInt 2 (DivideInt .Nodes 100)}}
      turnOffLoggingToFile: {{$TURN_OFF_LOGGING_TO_FILE_FOR_PROBES}}
{{if $ENABLE_NODE_LOCAL_DNS_LATENCY}}
  - Identifier: NodeLocalDNSLatency
    Method: NodeLocalDNSLatencyPrometheus
    Params:
      action: start
{{end}}
  - Identifier: SLOMeasurement
    Method: SLOMeasurement
    Params:
      action: start
      checkProbesReadyTimeout: {{$PROBE_MEASUREMENTS_CHECK_PROBES_READY_TIMEOUT}}
      replicasPerProbe: {{AddInt 2 (DivideInt .Nodes 100)}}
      turnOffLoggingToFile: {{$TURN_OFF_LOGGING_TO_FILE_FOR_PROBES}}
  {{if $PROMETHEUS_SCRAPE_KUBE_PROXY}}
  - Identifier: NetworkProgrammingLatency
    Method: NetworkProgrammingLatency
    Params:
      action: start
  {{end}}
  {{if $ENABLE_API_AVAILABILITY_MEASUREMENT}}
  - Identifier: APIAvailability
    Method: APIAvailability
    Params:
      action: start
      pollFrequency: "5s"
      hostPollTimeoutSeconds: 5
  {{end}}
  - Identifier: TestMetrics
    Method: TestMetrics
    Params:
      action: start
      systemPodMetricsEnabled: {{$ENABLE_SYSTEM_POD_METRICS}}
      clusterOOMsTrackerEnabled: {{$ENABLE_CLUSTER_OOMS_TRACKER}}
      clusterOOMsIgnoredProcesses: {{$CLUSTER_OOMS_IGNORED_PROCESSES}}
      restartCountThresholdOverrides: {{YamlQuote $RESTART_COUNT_THRESHOLD_OVERRIDES 4}}
      enableRestartCountCheck: {{$ENABLE_RESTART_COUNT_CHECK}}

- module:
    path: modules/services.yaml
    params:
      actionName: "Creating"
      namespaces: {{$namespaces}}
      smallServicesPerNamespace: {{DivideInt (AddInt $smallDeploymentsPerNamespace 1) 2}}
      mediumServicesPerNamespace: {{DivideInt (AddInt $mediumDeploymentsPerNamespace 1) 2}}
      bigServicesPerNamespace: {{DivideInt (AddInt $bigDeploymentsPerNamespace 1) 2}}

- name: Creating PriorityClass for DaemonSets
  phases:
  - replicasPerNamespace: 1
    tuningSet: Sequence
    objectBundle:
      - basename: daemonset-priorityclass
        objectTemplatePath: daemonset-priorityclass.yaml

- name: Starting measurement for waiting for pods
  measurements:
  - Method: WaitForControlledPodsRunning
    Instances:
    - Identifier: WaitForRunningDeployments
      Params:
        apiVersion: apps/v1
        kind: Deployment
    - Identifier: WaitForRunningStatefulSets
      Params:
        apiVersion: apps/v1
        kind: StatefulSet
    - Identifier: WaitForRunningDaemonSets
      Params:
        apiVersion: apps/v1
        kind: DaemonSet
    - Identifier: WaitForRunningJobs
      Params:
        apiVersion: batch/v1
        kind: Job
    Params:
      action: start
      labelSelector: group = load
      operationTimeout: 15m
      checkIfPodsAreUpdated: {{$CHECK_IF_PODS_ARE_UPDATED}}

- name: Creating objects
  phases:
{{if not $DISABLE_DAEMONSETS}}
  - namespaceRange:
      min: 1
      max: 1
    replicasPerNamespace: 1
    tuningSet: RandomizedSaturationTimeLimited
    objectBundle:
    - basename: daemonset
      objectTemplatePath: daemonset.yaml
      templateFillMap:
        Image: k8s.gcr.io/pause:3.0
{{end}}
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: {{$bigDeploymentsPerNamespace}}
    tuningSet: RandomizedSaturationTimeLimited
    objectBundle:
    - basename: big-deployment
      objectTemplatePath: configmap.yaml
    - basename: big-deployment
      objectTemplatePath: secret.yaml
    {{if $ENABLE_NETWORKPOLICIES}}
    - basename: big-deployment
      objectTemplatePath: networkpolicy.yaml
    {{end}}
    - basename: big-deployment
      objectTemplatePath: deployment.yaml
      templateFillMap:
        # DNS Test clients are enabled only in the medium-size deployment.
        EnableDNSTests: false
        ReplicasMin: {{$BIG_GROUP_SIZE}}
        ReplicasMax: {{$BIG_GROUP_SIZE}}
        SvcName: big-service
        CpuRequest: 5m
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: {{$mediumDeploymentsPerNamespace}}
    tuningSet: RandomizedSaturationTimeLimited
    objectBundle:
    - basename: medium-deployment
      objectTemplatePath: configmap.yaml
    - basename: medium-deployment
      objectTemplatePath: secret.yaml
    {{if $ENABLE_NETWORKPOLICIES}}
    - basename: medium-deployment
      objectTemplatePath: networkpolicy.yaml
    {{end}}
    - basename: medium-deployment
      objectTemplatePath: deployment.yaml
      templateFillMap:
        EnableDNSTests: {{$ENABLE_DNSTESTS}}
        ReplicasMin: {{$MEDIUM_GROUP_SIZE}}
        ReplicasMax: {{$MEDIUM_GROUP_SIZE}}
        SvcName: medium-service
        CpuRequest: 5m
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: {{$smallDeploymentsPerNamespace}}
    tuningSet: RandomizedSaturationTimeLimited
    objectBundle:
    - basename: small-deployment
      objectTemplatePath: configmap.yaml
    - basename: small-deployment
      objectTemplatePath: secret.yaml
    {{if $ENABLE_NETWORKPOLICIES}}
    - basename: small-deployment
      objectTemplatePath: networkpolicy.yaml
    {{end}}
    - basename: small-deployment
      objectTemplatePath: deployment.yaml
      templateFillMap:
        # DNS Test clients are enabled only in the medium-size deployment.
        EnableDNSTests: false
        ReplicasMin: {{$SMALL_GROUP_SIZE}}
        ReplicasMax: {{$SMALL_GROUP_SIZE}}
        SvcName: small-service
        CpuRequest: 5m
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: {{$SMALL_STATEFUL_SETS_PER_NAMESPACE}}
    tuningSet: RandomizedSaturationTimeLimited
    objectBundle:
      - basename: small-statefulset
        objectTemplatePath: statefulset_service.yaml
      - basename: small-statefulset
        objectTemplatePath: statefulset.yaml
        templateFillMap:
          ReplicasMin: {{$SMALL_GROUP_SIZE}}
          ReplicasMax: {{$SMALL_GROUP_SIZE}}
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: {{$MEDIUM_STATEFUL_SETS_PER_NAMESPACE}}
    tuningSet: RandomizedSaturationTimeLimited
    objectBundle:
      - basename: medium-statefulset
        objectTemplatePath: statefulset_service.yaml
      - basename: medium-statefulset
        objectTemplatePath: statefulset.yaml
        templateFillMap:
          ReplicasMin: {{$MEDIUM_GROUP_SIZE}}
          ReplicasMax: {{$MEDIUM_GROUP_SIZE}}
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: 1
    tuningSet: RandomizedSaturationTimeLimited
    objectBundle:
      - basename: small-job
        objectTemplatePath: job.yaml
        templateFillMap:
          ReplicasMin: {{$SMALL_GROUP_SIZE}}
          ReplicasMax: {{$SMALL_GROUP_SIZE}}
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: 1
    tuningSet: RandomizedSaturationTimeLimited
    objectBundle:
      - basename: medium-job
        objectTemplatePath: job.yaml
        templateFillMap:
          ReplicasMin: {{$MEDIUM_GROUP_SIZE}}
          ReplicasMax: {{$MEDIUM_GROUP_SIZE}}
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: {{$bigJobsPerNamespace}}
    tuningSet: RandomizedSaturationTimeLimited
    objectBundle:
      - basename: big-job
        objectTemplatePath: job.yaml
        templateFillMap:
          ReplicasMin: {{$BIG_GROUP_SIZE}}
          ReplicasMax: {{$BIG_GROUP_SIZE}}

- name: Waiting for pods to be running
  measurements:
  - Method: WaitForControlledPodsRunning
    Instances:
     - Identifier: WaitForRunningDeployments
     - Identifier: WaitForRunningStatefulSets
     - Identifier: WaitForRunningDaemonSets
     - Identifier: WaitForRunningJobs
    Params:
      action: gather

{{if $EXEC_COMMAND}}

{{if $ENABLE_API_AVAILABILITY_MEASUREMENT}}
- name: Pausing APIAvailability measurement
  measurements:
  - Identifier: APIAvailability
    Method: APIAvailability
    Params:
      action: pause
{{end}}

- name: Exec command
  measurements:
  - Identifier: ExecCommand
    Method: Exec
    Params:
      command:
      {{range $EXEC_COMMAND}}
      - {{.}}
      {{end}}

{{if $ENABLE_API_AVAILABILITY_MEASUREMENT}}
- name: Unpausing APIAvailability measurement
  measurements:
  - Identifier: APIAvailability
    Method: APIAvailability
    Params:
      action: unpause
{{end}}

- name: Sleep
  measurements:
  - Identifier: WaitAfterExec
    Method: Sleep
    Params:
      duration: {{$SLEEP_AFTER_EXEC_DURATION}}
{{end}}
{{if not $EXIT_AFTER_EXEC}}

{{if not $IS_SMALL_CLUSTER}}
# BEGIN scheduler throughput
- name: Creating scheduler throughput measurements
  measurements:
  - Identifier: HighThroughputPodStartupLatency
    Method: PodStartupLatency
    Params:
      action: start
      labelSelector: group = scheduler-throughput
      threshold: 1h # TODO(https://github.com/kubernetes/perf-tests/issues/1024): Ideally, this should be 5s
  - Identifier: WaitForSchedulerThroughputDeployments
    Method: WaitForControlledPodsRunning
    Params:
      action: start
      apiVersion: apps/v1
      kind: Deployment
      labelSelector: group = scheduler-throughput
      # The operation timeout shouldn't be less than 20m to make sure that ~10m node
      # failure won't fail the test. See https://github.com/kubernetes/kubernetes/issues/73461#issuecomment-467338711
      operationTimeout: 20m
  - Identifier: SchedulingThroughput
    Method: SchedulingThroughput
    Params:
      action: start
      labelSelector: group = scheduler-throughput
      measurmentInterval: 1s
{{if $ENABLE_HUGE_SERVICES}}
- name: Creating huge services
  phases:
  - namespaceRange:
      min: {{AddInt $namespaces 1}}
      max: {{AddInt $namespaces $schedulerThroughputNamespaces}}
    replicasPerNamespace: 1
    tuningSet: Sequence
    objectBundle:
    - basename: huge-service
      objectTemplatePath: service.yaml
{{end}}
- name: Creating scheduler throughput pods
  phases:
  - namespaceRange:
      min: {{AddInt $namespaces 1}}
      max: {{AddInt $namespaces $schedulerThroughputNamespaces}}
    replicasPerNamespace: 1
    tuningSet: SchedulerThroughputParallel
    objectBundle:
    - basename: scheduler-throughput-deployment
      objectTemplatePath: simple-deployment.yaml
      templateFillMap:
        Replicas: {{$schedulerThroughputPodsPerDeployment}}
        Group: scheduler-throughput
        CpuRequest: 1m
        MemoryRequest: 10M
{{if $ENABLE_HUGE_SERVICES}}
        SvcName: huge-service
{{end}}
- name: Waiting for scheduler throughput pods to be created
  measurements:
  - Identifier: WaitForSchedulerThroughputDeployments
    Method: WaitForControlledPodsRunning
    Params:
      action: gather
- name: Collecting scheduler throughput measurements
  measurements:
  - Identifier: HighThroughputPodStartupLatency
    Method: PodStartupLatency
    Params:
      action: gather
  - Identifier: SchedulingThroughput
    Method: SchedulingThroughput
    Params:
      action: gather
      enableViolations: true
      threshold: {{$schedulerThroughputThreshold}}
- name: Deleting scheduler throughput pods
  phases:
  - namespaceRange:
      min: {{AddInt $namespaces 1}}
      max: {{AddInt $namespaces $schedulerThroughputNamespaces}}
    replicasPerNamespace: 0
    tuningSet: SchedulerThroughputParallel
    objectBundle:
    - basename: scheduler-throughput-deployment
      objectTemplatePath: simple-deployment.yaml
- name: Waiting for scheduler throughput pods to be deleted
  measurements:
  - Identifier: WaitForSchedulerThroughputDeployments
    Method: WaitForControlledPodsRunning
    Params:
      action: gather
{{if $ENABLE_HUGE_SERVICES}}
- name: Deleting huge services
  phases:
  - namespaceRange:
      min: {{AddInt $namespaces 1}}
      max: {{AddInt $namespaces $schedulerThroughputNamespaces}}
    replicasPerNamespace: 0
    tuningSet: Sequence
    objectBundle:
    - basename: huge-service
      objectTemplatePath: service.yaml
- name: Sleeping after deleting huge services
  measurements:
  - Identifier: WaitAfterHugeServicesDeletion
    Method: Sleep
    Params:
      duration: "3m"
{{end}}
# END scheduler throughput
{{end}}

{{if not $IS_SMALL_CLUSTER}}
# TODO(kubernetes/perf-tests/issues/1024): We shouldn't have a dedicated module for measuring pod-startup-latency.
- module:
    path: modules/pod-startup-latency.yaml
    params:
      namespaces: {{$namespaces}}
      minPodsInSmallCluster: {{$MIN_PODS_IN_SMALL_CLUSTERS}}
{{end}}

- name: Scaling and updating objects
  phases:
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: {{$bigDeploymentsPerNamespace}}
    tuningSet: RandomizedScalingTimeLimited
    objectBundle:
    - basename: big-deployment
      objectTemplatePath: deployment.yaml
      templateFillMap:
        # DNS Test clients are enabled only in the medium-size deployment.
        EnableDNSTests: false
        ReplicasMin: {{MultiplyInt $BIG_GROUP_SIZE 0.5}}
        ReplicasMax: {{MultiplyInt $BIG_GROUP_SIZE 1.5}}
        SvcName: big-service
        CpuRequest: 5m
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: {{$mediumDeploymentsPerNamespace}}
    tuningSet: RandomizedScalingTimeLimited
    objectBundle:
    - basename: medium-deployment
      objectTemplatePath: deployment.yaml
      templateFillMap:
        EnableDNSTests: {{$ENABLE_DNSTESTS}}
        ReplicasMin: {{MultiplyInt $MEDIUM_GROUP_SIZE 0.5}}
        ReplicasMax: {{MultiplyInt $MEDIUM_GROUP_SIZE 1.5}}
        SvcName: medium-service
        CpuRequest: 5m
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: {{$smallDeploymentsPerNamespace}}
    tuningSet: RandomizedScalingTimeLimited
    objectBundle:
    - basename: small-deployment
      objectTemplatePath: deployment.yaml
      templateFillMap:
        # DNS Test clients are enabled only in the medium-size deployment.
        EnableDNSTests: false
        ReplicasMin: {{MultiplyInt $SMALL_GROUP_SIZE 0.5}}
        ReplicasMax: {{MultiplyInt $SMALL_GROUP_SIZE 1.5}}
        SvcName: small-service
        CpuRequest: 5m
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: {{$SMALL_STATEFUL_SETS_PER_NAMESPACE}}
    tuningSet: RandomizedScalingTimeLimited
    objectBundle:
      - basename: small-statefulset
        objectTemplatePath: statefulset.yaml
        templateFillMap:
          ReplicasMin: {{MultiplyInt $SMALL_GROUP_SIZE 0.5}}
          ReplicasMax: {{MultiplyInt $SMALL_GROUP_SIZE 1.5}}
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: {{$MEDIUM_STATEFUL_SETS_PER_NAMESPACE}}
    tuningSet: RandomizedScalingTimeLimited
    objectBundle:
      - basename: medium-statefulset
        objectTemplatePath: statefulset.yaml
        templateFillMap:
          ReplicasMin: {{MultiplyInt $MEDIUM_GROUP_SIZE 0.5}}
          ReplicasMax: {{MultiplyInt $MEDIUM_GROUP_SIZE 1.5}}
{{if not $DISABLE_DAEMONSETS}}
  - namespaceRange:
      min: 1
      max: 1
    replicasPerNamespace: 1
    tuningSet: RandomizedScalingTimeLimited
    objectBundle:
      - basename: daemonset
        objectTemplatePath: daemonset.yaml
        templateFillMap:
          Image: k8s.gcr.io/pause:3.1
{{end}}
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: 1
    tuningSet: RandomizedScalingTimeLimited
    objectBundle:
      - basename: small-job
        objectTemplatePath: job.yaml
        templateFillMap:
          ReplicasMin: {{MultiplyInt $SMALL_GROUP_SIZE 0.5}}
          ReplicasMax: {{MultiplyInt $SMALL_GROUP_SIZE 1.5}}
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: 1
    tuningSet: RandomizedScalingTimeLimited
    objectBundle:
      - basename: medium-job
        objectTemplatePath: job.yaml
        templateFillMap:
          ReplicasMin: {{MultiplyInt $MEDIUM_GROUP_SIZE 0.5}}
          ReplicasMax: {{MultiplyInt $MEDIUM_GROUP_SIZE 1.5}}
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: {{$bigJobsPerNamespace}}
    tuningSet: RandomizedScalingTimeLimited
    objectBundle:
      - basename: big-job
        objectTemplatePath: job.yaml
        templateFillMap:
          ReplicasMin: {{MultiplyInt $BIG_GROUP_SIZE 0.5}}
          ReplicasMax: {{MultiplyInt $BIG_GROUP_SIZE 1.5}}

- name: Waiting for objects to become scaled
  measurements:
  - Method: WaitForControlledPodsRunning
    Instances:
    - Identifier: WaitForRunningDeployments
    - Identifier: WaitForRunningStatefulSets
    - Identifier: WaitForRunningDaemonSets
    - Identifier: WaitForRunningJobs
    Params:
      action: gather

- name: Deleting objects
  phases:
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: 0
    tuningSet: RandomizedDeletionTimeLimited
    objectBundle:
    - basename: big-deployment
      objectTemplatePath: deployment.yaml
    - basename: big-deployment
      objectTemplatePath: configmap.yaml
    - basename: big-deployment
      objectTemplatePath: secret.yaml
    {{if $ENABLE_NETWORKPOLICIES}}
    - basename: big-deployment
      objectTemplatePath: networkpolicy.yaml
    {{end}}
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: 0
    tuningSet: RandomizedDeletionTimeLimited
    objectBundle:
    - basename: medium-deployment
      objectTemplatePath: deployment.yaml
    - basename: medium-deployment
      objectTemplatePath: configmap.yaml
    - basename: medium-deployment
      objectTemplatePath: secret.yaml
    {{if $ENABLE_NETWORKPOLICIES}}
    - basename: medium-deployment
      objectTemplatePath: networkpolicy.yaml
    {{end}}
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: 0
    tuningSet: RandomizedDeletionTimeLimited
    objectBundle:
    - basename: small-deployment
      objectTemplatePath: deployment.yaml
    - basename: small-deployment
      objectTemplatePath: configmap.yaml
    - basename: small-deployment
      objectTemplatePath: secret.yaml
    {{if $ENABLE_NETWORKPOLICIES}}
    - basename: small-deployment
      objectTemplatePath: networkpolicy.yaml
    {{end}}
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: 0
    tuningSet: RandomizedDeletionTimeLimited
    objectBundle:
      - basename: small-statefulset
        objectTemplatePath: statefulset.yaml
      - basename: small-statefulset
        objectTemplatePath: statefulset_service.yaml
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: 0
    tuningSet: RandomizedDeletionTimeLimited
    objectBundle:
      - basename: medium-statefulset
        objectTemplatePath: statefulset.yaml
      - basename: medium-statefulset
        objectTemplatePath: statefulset_service.yaml
  - namespaceRange:
      min: 1
      max: 1
    replicasPerNamespace: 0
    tuningSet: RandomizedDeletionTimeLimited
    objectBundle:
      - basename: daemonset
        objectTemplatePath: daemonset.yaml
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: 0
    tuningSet: RandomizedDeletionTimeLimited
    objectBundle:
      - basename: small-job
        objectTemplatePath: job.yaml
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: 0
    tuningSet: RandomizedDeletionTimeLimited
    objectBundle:
      - basename: medium-job
        objectTemplatePath: job.yaml
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: 0
    tuningSet: RandomizedDeletionTimeLimited
    objectBundle:
      - basename: big-job
        objectTemplatePath: job.yaml
  # If both StatefulSets and PVs were enabled we need to delete PVs manually.
  {{if $ENABLE_PVS}}
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: 0
    tuningSet: RandomizedDeletionTimeLimited
    objectBundle:
      {{range $ssIndex := Loop $SMALL_STATEFUL_SETS_PER_NAMESPACE}}
      - basename: pv-small-statefulset-{{$ssIndex}}
        objectTemplatePath: pvc.yaml
        listUnknownObjectOptions:
          labelSelector:
            matchLabels:
              name: small-statefulset-{{$ssIndex}}
      {{end}}
  - namespaceRange:
      min: 1
      max: {{$namespaces}}
    replicasPerNamespace: 0
    tuningSet: RandomizedDeletionTimeLimited
    objectBundle:
      {{range $ssIndex := Loop $MEDIUM_STATEFUL_SETS_PER_NAMESPACE}}
      - basename: pv-medium-statefulset-{{$ssIndex}}
        objectTemplatePath: pvc.yaml
        listUnknownObjectOptions:
          labelSelector:
            matchLabels:
              name: medium-statefulset-{{$ssIndex}}
      {{end}}
  {{end}}

- name: Waiting for pods to be deleted
  measurements:
  - Method: WaitForControlledPodsRunning
    Instances:
     - Identifier: WaitForRunningDeployments
     - Identifier: WaitForRunningStatefulSets
     - Identifier: WaitForRunningDaemonSets
     - Identifier: WaitForRunningJobs
    Params:
      action: gather
  {{if $ENABLE_PVS}}
  - Identifier: WaitForPVCsToBeDeleted
    Method: WaitForBoundPVCs
    Params:
      desiredPVCCount: 0
      labelSelector: group = load
      timeout: 15m
  {{end}}

- name: Deleting PriorityClass for DaemonSets
  phases:
    - replicasPerNamespace: 0
      tuningSet: Sequence
      objectBundle:
        - basename: daemonset-priorityclass
          objectTemplatePath: daemonset-priorityclass.yaml

- module:
    path: modules/services.yaml
    params:
      actionName: "Deleting"
      namespaces: {{$namespaces}}
      smallServicesPerNamespace: 0
      mediumServicesPerNamespace: 0
      bigServicesPerNamespace: 0
{{end}} # not EXIT_AFTER_EXEC

- name: Collecting measurements
  measurements:
  - Identifier: APIResponsivenessPrometheusSimple
    Method: APIResponsivenessPrometheus
    Params:
      action: gather
      enableViolations: {{$ENABLE_VIOLATIONS_FOR_API_CALL_PROMETHEUS_SIMPLE}}
      useSimpleLatencyQuery: true
      summaryName: APIResponsivenessPrometheus_simple
      allowedSlowCalls: {{$ALLOWED_SLOW_API_CALLS}}
      customThresholds: {{YamlQuote $CUSTOM_API_CALL_THRESHOLDS 4}}
  {{if not $USE_SIMPLE_LATENCY_QUERY}}
  - Identifier: APIResponsivenessPrometheus
    Method: APIResponsivenessPrometheus
    Params:
      action: gather
      enableViolations: {{$ENABLE_VIOLATIONS_FOR_API_CALL_PROMETHEUS}}
      allowedSlowCalls: {{$ALLOWED_SLOW_API_CALLS}}
      customThresholds: {{YamlQuote $CUSTOM_API_CALL_THRESHOLDS 4}}
  {{end}}
  - Identifier: CreatePhasePodStartupLatency
    Method: PodStartupLatency
    Params:
      action: gather
  - Identifier: InClusterNetworkLatency
    Method: InClusterNetworkLatency
    Params:
      action: gather
{{if $ENABLE_NODE_LOCAL_DNS_LATENCY}}
  - Identifier: NodeLocalDNSLatency
    Method: NodeLocalDNSLatencyPrometheus
    Params:
      action: gather
      enableViolations: true
      threshold: {{$NODE_LOCAL_DNS_LATENCY_THRESHOLD}}
{{end}}
  - Identifier: SLOMeasurement
    Method: SLOMeasurement
    Params:
      action: gather
  {{if $PROMETHEUS_SCRAPE_KUBE_PROXY}}
  - Identifier: NetworkProgrammingLatency
    Method: NetworkProgrammingLatency
    Params:
      action: gather
  {{end}}
  {{if $ENABLE_API_AVAILABILITY_MEASUREMENT}}
  - Identifier: APIAvailability
    Method: APIAvailability
    Params:
      action: gather
  {{end}}
  - Identifier: TestMetrics
    Method: TestMetrics
    Params:
      action: gather
      systemPodMetricsEnabled: {{$ENABLE_SYSTEM_POD_METRICS}}
      clusterOOMsTrackerEnabled: {{$ENABLE_CLUSTER_OOMS_TRACKER}}
      restartCountThresholdOverrides: {{YamlQuote $RESTART_COUNT_THRESHOLD_OVERRIDES 4}}
      enableRestartCountCheck: {{$ENABLE_RESTART_COUNT_CHECK}}
