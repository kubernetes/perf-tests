# ASSUMPTIONS:
# - Underlying cluster should have 100+ nodes.
# See https://github.com/kubernetes/perf-tests/pull/1667#issuecomment-769642266

# The minimal number of pods to be used to measure various things like
# pod-startup-latency or scheduler-throughput. The purpose of it is to avoid
# problems in small clusters where we wouldn't have enough samples (pods) to
# measure things accurately.
# TODO( https://github.com/kubernetes/perf-tests/issues/1027): Lower the number of "min-pods" once we fix the scheduler throughput measurement.
{{$MIN_PODS_IN_SMALL_CLUSTERS := 5000}}

{{$totalSchedulerThroughputPods := DefaultParam .CL2_SCHEDULER_THROUGHPUT_PODS $MIN_PODS_IN_SMALL_CLUSTERS}}
{{$defaultQps := DefaultParam .CL2_DEFAULT_QPS  500}}
{{$defaultBurst := DefaultParam .CL2_DEFAULT_BURST 1000}}
{{$uniformQps := DefaultParam .CL2_UNIFORM_QPS 500}}

{{$SCHEDULER_THROUGHPUT_THRESHOLD := DefaultParam .CL2_SCHEDULER_THROUGHPUT_THRESHOLD 400}}

name: direct-scheduler-throughput
namespace:
  number: 1
tuningSets:
# default is a tuningset that is meant to be used when we don't have any specific requirements on pace of operations.
- name: default
  globalQPSLoad:
    qps: {{$defaultQps}}
    burst: {{$defaultBurst}}
- name: UniformQPS
  qpsLoad:
    qps: {{$uniformQps}}
steps:
- name: Creating scheduler throughput measurements
  measurements:
  - Identifier: DirectSchedulerThroughputPodStartupLatency
    Method: PodStartupLatency
    Params:
      action: start
      labelSelector: group = direct-scheduler-throughput
      threshold: 5s
  - Identifier: DirectSchedulingThroughput
    Method: SchedulingThroughput
    Params:
      action: start
      labelSelector: group = direct-scheduler-throughput
      measurmentInterval: 1s
- name: create scheduler throughput pods
  phases:
  - namespaceRange:
      min: 1
      max: 1
    replicasPerNamespace: {{$totalSchedulerThroughputPods}}
    tuningSet: UniformQPS
    objectBundle:
    - basename: direct-scheduler-throughput-pod
      objectTemplatePath: pod-default.yaml
      templateFillMap:
        Group: direct-scheduler-throughput
- name: Waiting for scheduler throughput pods to be created
  measurements:
  - Identifier: WaitForDirectSchedulerThroughputPods
    Method: WaitForRunningPods
    Params:
      action: gather
      timeout: 5m
      desiredPodCount: {{$totalSchedulerThroughputPods}}
      labelSelector: group = direct-scheduler-throughput
- name: Collecting scheduler throughput measurements
  measurements:
  - Identifier: DirectSchedulerThroughputPodStartupLatency
    Method: PodStartupLatency
    Params:
      action: gather
  - Identifier: DirectSchedulingThroughput
    Method: SchedulingThroughput
    Params:
      action: gather
      enableViolations: true
      threshold: {{$SCHEDULER_THROUGHPUT_THRESHOLD}}
- name: Delete scheduler throughput pods
  phases:
  - namespaceRange:
      min: 1
      max: 1
    replicasPerNamespace: 0
    tuningSet: default
    objectBundle:
    - basename: scheduler-throughput-pod
      objectTemplatePath: pod-default.yaml
      templateFillMap:
        Group: direct-scheduler-throughput